{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67858fab",
   "metadata": {},
   "source": [
    "# Assignment 8: Ensemble-Based Classifier\n",
    "### DSC-540\n",
    "### David Bui\n",
    "\n",
    "# Dataset\n",
    "Description: This dataset contains info in the matters of body movement during several activities. The goal of this learning model is to implement the ensemble method with 4 models and follow the instructions written within this article. https://journals.lww.com/acsm-msse/Fulltext/2017/09000/Ensemble_Methods_for_Classification_of_Physical.24.aspx\n",
    "\n",
    "Source: UCI Machine Learning Repository\n",
    "Link: http://archive.ics.uci.edu/ml/datasets/pamap2+physical+activity+monitoring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "38a75191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB # For the Behavior Knowledge Space\n",
    "from sklearn.naive_bayes import GaussianNB # Naive Bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e63f4",
   "metadata": {},
   "source": [
    "# Initializing the Dataset \n",
    "There 9 dat files which represent the 9 test subjects. It is composed of 8 males and 1 female. These dat files are combined into a single text file and then placed into a dataframe. The data goes through several layers of filtering and feature selection before handing the newly formed data over to the learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dd9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # for the file merging\n",
    "path = '..\\OneDrive\\Desktop\\GCU Studies\\DSC-540\\Topic 8\\Assignment\\Data'\n",
    "\n",
    "file_list = os.listdir(path)\n",
    "for filename in sorted(file_list):\n",
    "    out_filename = 'pamap.txt'\n",
    "    with open(out_filename, 'a') as outfile:\n",
    "        with open(path + '/' + filename, 'r') as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3b1843f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>heartrate</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>z-axis</th>\n",
       "      <th>w1</th>\n",
       "      <th>w2</th>\n",
       "      <th>w3</th>\n",
       "      <th>w4</th>\n",
       "      <th>w5</th>\n",
       "      <th>w6</th>\n",
       "      <th>w7</th>\n",
       "      <th>w8</th>\n",
       "      <th>w9</th>\n",
       "      <th>w10</th>\n",
       "      <th>w11</th>\n",
       "      <th>w12</th>\n",
       "      <th>w13</th>\n",
       "      <th>w14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.38</td>\n",
       "      <td>0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.37223</td>\n",
       "      <td>8.60074</td>\n",
       "      <td>3.51048</td>\n",
       "      <td>2.43954</td>\n",
       "      <td>8.76165</td>\n",
       "      <td>3.35465</td>\n",
       "      <td>-0.092217</td>\n",
       "      <td>0.056812</td>\n",
       "      <td>-0.015845</td>\n",
       "      <td>14.6806</td>\n",
       "      <td>-69.2128</td>\n",
       "      <td>-5.58905</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.39</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.18837</td>\n",
       "      <td>8.56560</td>\n",
       "      <td>3.66179</td>\n",
       "      <td>2.39494</td>\n",
       "      <td>8.55081</td>\n",
       "      <td>3.64207</td>\n",
       "      <td>-0.024413</td>\n",
       "      <td>0.047759</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>14.8991</td>\n",
       "      <td>-69.2224</td>\n",
       "      <td>-5.82311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.40</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.37357</td>\n",
       "      <td>8.60107</td>\n",
       "      <td>3.54898</td>\n",
       "      <td>2.30514</td>\n",
       "      <td>8.53644</td>\n",
       "      <td>3.73280</td>\n",
       "      <td>-0.057976</td>\n",
       "      <td>0.032574</td>\n",
       "      <td>-0.006988</td>\n",
       "      <td>14.2420</td>\n",
       "      <td>-69.5197</td>\n",
       "      <td>-5.12442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.41</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.07473</td>\n",
       "      <td>8.52853</td>\n",
       "      <td>3.66021</td>\n",
       "      <td>2.33528</td>\n",
       "      <td>8.53622</td>\n",
       "      <td>3.73277</td>\n",
       "      <td>-0.002352</td>\n",
       "      <td>0.032810</td>\n",
       "      <td>-0.003747</td>\n",
       "      <td>14.8908</td>\n",
       "      <td>-69.5439</td>\n",
       "      <td>-6.17367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.42</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.22936</td>\n",
       "      <td>8.83122</td>\n",
       "      <td>3.70000</td>\n",
       "      <td>2.23055</td>\n",
       "      <td>8.59741</td>\n",
       "      <td>3.76295</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.018305</td>\n",
       "      <td>-0.053325</td>\n",
       "      <td>15.5612</td>\n",
       "      <td>-68.8196</td>\n",
       "      <td>-6.28927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  activityID  heartrate  x-axis   y-axis   z-axis       w1  \\\n",
       "0       8.38           0      104.0    30.0  2.37223  8.60074  3.51048   \n",
       "1       8.39           0        NaN    30.0  2.18837  8.56560  3.66179   \n",
       "2       8.40           0        NaN    30.0  2.37357  8.60107  3.54898   \n",
       "3       8.41           0        NaN    30.0  2.07473  8.52853  3.66021   \n",
       "4       8.42           0        NaN    30.0  2.22936  8.83122  3.70000   \n",
       "\n",
       "        w2       w3       w4        w5        w6        w7       w8       w9  \\\n",
       "0  2.43954  8.76165  3.35465 -0.092217  0.056812 -0.015845  14.6806 -69.2128   \n",
       "1  2.39494  8.55081  3.64207 -0.024413  0.047759  0.006474  14.8991 -69.2224   \n",
       "2  2.30514  8.53644  3.73280 -0.057976  0.032574 -0.006988  14.2420 -69.5197   \n",
       "3  2.33528  8.53622  3.73277 -0.002352  0.032810 -0.003747  14.8908 -69.5439   \n",
       "4  2.23055  8.59741  3.76295  0.012269  0.018305 -0.053325  15.5612 -68.8196   \n",
       "\n",
       "       w10  w11  w12  w13  w14  \n",
       "0 -5.58905  1.0  0.0  0.0  0.0  \n",
       "1 -5.82311  1.0  0.0  0.0  0.0  \n",
       "2 -5.12442  1.0  0.0  0.0  0.0  \n",
       "3 -6.17367  1.0  0.0  0.0  0.0  \n",
       "4 -6.28927  1.0  0.0  0.0  0.0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['timestamp', 'activityID', 'heartrate', 'x-axis', 'y-axis', 'z-axis', 'w1', 'w2', 'w3'\n",
    "        ,'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14']\n",
    "\n",
    "df = pd.read_csv('pamap.txt', ' ', header=None)\n",
    "df.drop(df.iloc[:, 20:], axis = 1, inplace=True)\n",
    "df.columns=cols\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f206c",
   "metadata": {},
   "source": [
    "### Preprocessing:\n",
    "Under ActivityID the '0' element was removed because it represented 'other' which gives little to no value for interpretation or distinction. The 'other' activity is also quite significant in size, being nearly 4 times the size of the 2nd largest activity. WIthin the article they focus on hand and wrist movement, which allows reason for a feature dimension reduction. Lastly, null elements can be found, which attribute to roughly 0.0057% of the data. Due to the size of the dataframe imputation would be quiet lenthy, for this reason they are simply removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "008b664e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN elements:  0\n"
     ]
    }
   ],
   "source": [
    "# filling missing data\n",
    "def clean_data(df):\n",
    "    # removing data with transient activity\n",
    "    df = df.drop(df[df['activityID']==0].index)\n",
    "    # remove non-numeric data cells\n",
    "    df = df.apply(pd.to_numeric, errors = 'coerce')\n",
    "    # fill in NaN values using iterpolation which is what they used in the article.\n",
    "    df = df.interpolate()\n",
    "    return df\n",
    "  \n",
    "df = clean_data(df)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "df.drop('heartrate', inplace=True, axis=1)\n",
    "print('Number of NaN elements: ',df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "d980b9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>z-axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.257309e+06</td>\n",
       "      <td>1.257309e+06</td>\n",
       "      <td>1.257309e+06</td>\n",
       "      <td>1.257309e+06</td>\n",
       "      <td>1.257309e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.791470e+03</td>\n",
       "      <td>3.883755e+00</td>\n",
       "      <td>3.230984e+01</td>\n",
       "      <td>-4.515079e+00</td>\n",
       "      <td>3.534577e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.244218e+03</td>\n",
       "      <td>2.013225e+00</td>\n",
       "      <td>1.786229e+00</td>\n",
       "      <td>6.788416e+00</td>\n",
       "      <td>7.683087e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.766000e+01</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.750000e+01</td>\n",
       "      <td>-1.453670e+02</td>\n",
       "      <td>-1.043010e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.357500e+02</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>3.093750e+01</td>\n",
       "      <td>-9.025740e+00</td>\n",
       "      <td>8.734870e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.289190e+03</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>3.268750e+01</td>\n",
       "      <td>-5.185620e+00</td>\n",
       "      <td>3.338140e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.908590e+03</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>3.368750e+01</td>\n",
       "      <td>9.808790e-02</td>\n",
       "      <td>6.283990e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.007810e+03</td>\n",
       "      <td>7.000000e+00</td>\n",
       "      <td>3.525000e+01</td>\n",
       "      <td>6.285960e+01</td>\n",
       "      <td>1.556990e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          timestamp    activityID        x-axis        y-axis        z-axis\n",
       "count  1.257309e+06  1.257309e+06  1.257309e+06  1.257309e+06  1.257309e+06\n",
       "mean   1.791470e+03  3.883755e+00  3.230984e+01 -4.515079e+00  3.534577e+00\n",
       "std    1.244218e+03  2.013225e+00  1.786229e+00  6.788416e+00  7.683087e+00\n",
       "min    3.766000e+01  1.000000e+00  2.750000e+01 -1.453670e+02 -1.043010e+02\n",
       "25%    5.357500e+02  2.000000e+00  3.093750e+01 -9.025740e+00  8.734870e-01\n",
       "50%    2.289190e+03  4.000000e+00  3.268750e+01 -5.185620e+00  3.338140e+00\n",
       "75%    2.908590e+03  6.000000e+00  3.368750e+01  9.808790e-02  6.283990e+00\n",
       "max    4.007810e+03  7.000000e+00  3.525000e+01  6.285960e+01  1.556990e+02"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WIthin the article 'other' which is 0 was removed from the study. It also would of created an imbalance\n",
    "# in the data which would effect the sampling methods later on. Heartrate is also dropped since they\n",
    "# are focusing on 3D acceleration only.\n",
    "df.drop(df[df['activityID'] == 0].index, inplace=True)\n",
    "df = df[['timestamp', 'activityID', 'x-axis', 'y-axis', 'z-axis']] # Dataset 1\n",
    "df = df.loc[df['activityID'] < 9]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a939d5",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3fc390eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257309, 5)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing of 10 second windows with 50% overlapping\n",
    "window = df['timestamp'].random()\n",
    "indexNames = df[(df['timestamp'] <= window-5) | (df['timestamp'] >= window+5)].index\n",
    "#indexNames = df[(df['timestamp'] <= df['timestamp'].min()-5) | (df['timestamp'] >= df['timestamp'].max()+5)].index\n",
    "\n",
    "# Here the dataframe is restricted into the select window slice.\n",
    "df.drop(indexNames , inplace=True)\n",
    "\n",
    "# Reset the index after doing all this\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "f156cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am not implementing the 25 and 75 percentiles, this is due to me reachings 45 features already,\n",
    "# which is the exact number used within the article and I'm trying to get as close to them as possible.\n",
    "sample = df.sample(n=5000)\n",
    "sample.reset_index(inplace=True)\n",
    "sample.drop('index', inplace=True, axis=1)\n",
    "t = sample.sample(n=10)\n",
    "\n",
    "series = t.agg(['sum','mean','var','std','skew','kurt','median','min','max']).unstack()\n",
    "\n",
    "new_df = pd.concat([sample,series.set_axis([f'{x}_{y}'\n",
    "                                for x, y in series.index])\n",
    "                                  .to_frame().T], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5f31f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(sample)):\n",
    "    t = sample.sample(n=10)\n",
    "    series = t.agg(['sum','mean','var','std','skew','kurt','median','min','max']).unstack()\n",
    "    \n",
    "    #new_df.loc[i, :] = series.set_axis([f'{x}_{y}' for x, y in series.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "373327bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>activityID</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>z-axis</th>\n",
       "      <th>timestamp_mean</th>\n",
       "      <th>timestamp_var</th>\n",
       "      <th>timestamp_std</th>\n",
       "      <th>timestamp_skew</th>\n",
       "      <th>timestamp_kurt</th>\n",
       "      <th>...</th>\n",
       "      <th>y-axis_min</th>\n",
       "      <th>y-axis_max</th>\n",
       "      <th>z-axis_mean</th>\n",
       "      <th>z-axis_var</th>\n",
       "      <th>z-axis_std</th>\n",
       "      <th>z-axis_skew</th>\n",
       "      <th>z-axis_kurt</th>\n",
       "      <th>z-axis_median</th>\n",
       "      <th>z-axis_min</th>\n",
       "      <th>z-axis_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>843.83</td>\n",
       "      <td>3</td>\n",
       "      <td>34.250</td>\n",
       "      <td>-8.41404</td>\n",
       "      <td>4.86328</td>\n",
       "      <td>2160.733</td>\n",
       "      <td>1.391820e+06</td>\n",
       "      <td>1179.754255</td>\n",
       "      <td>-0.683112</td>\n",
       "      <td>-1.076137</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.6690</td>\n",
       "      <td>6.77110</td>\n",
       "      <td>3.955801</td>\n",
       "      <td>18.754033</td>\n",
       "      <td>4.330593</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.209104</td>\n",
       "      <td>3.385215</td>\n",
       "      <td>-3.876750</td>\n",
       "      <td>11.03760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>720.36</td>\n",
       "      <td>3</td>\n",
       "      <td>33.250</td>\n",
       "      <td>-9.11462</td>\n",
       "      <td>2.97958</td>\n",
       "      <td>1818.260</td>\n",
       "      <td>1.726689e+06</td>\n",
       "      <td>1314.035502</td>\n",
       "      <td>-0.133315</td>\n",
       "      <td>-1.866330</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.2855</td>\n",
       "      <td>5.15601</td>\n",
       "      <td>5.059120</td>\n",
       "      <td>23.705820</td>\n",
       "      <td>4.868862</td>\n",
       "      <td>0.811003</td>\n",
       "      <td>-0.350633</td>\n",
       "      <td>3.827275</td>\n",
       "      <td>-0.649272</td>\n",
       "      <td>13.29150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.88</td>\n",
       "      <td>1</td>\n",
       "      <td>33.625</td>\n",
       "      <td>6.76227</td>\n",
       "      <td>2.89743</td>\n",
       "      <td>2108.648</td>\n",
       "      <td>2.172930e+06</td>\n",
       "      <td>1474.086143</td>\n",
       "      <td>-0.372840</td>\n",
       "      <td>-1.769826</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.5641</td>\n",
       "      <td>12.41910</td>\n",
       "      <td>7.476966</td>\n",
       "      <td>31.410942</td>\n",
       "      <td>5.604547</td>\n",
       "      <td>0.750276</td>\n",
       "      <td>-1.243794</td>\n",
       "      <td>5.326455</td>\n",
       "      <td>0.925382</td>\n",
       "      <td>15.89050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>607.92</td>\n",
       "      <td>3</td>\n",
       "      <td>34.000</td>\n",
       "      <td>-9.32691</td>\n",
       "      <td>2.75772</td>\n",
       "      <td>1954.612</td>\n",
       "      <td>1.544999e+06</td>\n",
       "      <td>1242.980012</td>\n",
       "      <td>-0.204804</td>\n",
       "      <td>-1.930438</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.2669</td>\n",
       "      <td>12.31840</td>\n",
       "      <td>2.758507</td>\n",
       "      <td>19.977624</td>\n",
       "      <td>4.469634</td>\n",
       "      <td>-0.527023</td>\n",
       "      <td>1.913948</td>\n",
       "      <td>2.881975</td>\n",
       "      <td>-6.676230</td>\n",
       "      <td>9.96933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>744.49</td>\n",
       "      <td>3</td>\n",
       "      <td>33.125</td>\n",
       "      <td>2.29445</td>\n",
       "      <td>7.96671</td>\n",
       "      <td>1798.173</td>\n",
       "      <td>1.703125e+06</td>\n",
       "      <td>1305.038129</td>\n",
       "      <td>-0.369391</td>\n",
       "      <td>-1.923656</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.6631</td>\n",
       "      <td>6.88393</td>\n",
       "      <td>5.550876</td>\n",
       "      <td>34.808410</td>\n",
       "      <td>5.899865</td>\n",
       "      <td>2.021176</td>\n",
       "      <td>5.310004</td>\n",
       "      <td>4.505560</td>\n",
       "      <td>-1.062830</td>\n",
       "      <td>20.57610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  activityID  x-axis   y-axis   z-axis  timestamp_mean  \\\n",
       "0     843.83           3  34.250 -8.41404  4.86328        2160.733   \n",
       "1     720.36           3  33.250 -9.11462  2.97958        1818.260   \n",
       "2     133.88           1  33.625  6.76227  2.89743        2108.648   \n",
       "3     607.92           3  34.000 -9.32691  2.75772        1954.612   \n",
       "4     744.49           3  33.125  2.29445  7.96671        1798.173   \n",
       "\n",
       "   timestamp_var  timestamp_std  timestamp_skew  timestamp_kurt  ...  \\\n",
       "0   1.391820e+06    1179.754255       -0.683112       -1.076137  ...   \n",
       "1   1.726689e+06    1314.035502       -0.133315       -1.866330  ...   \n",
       "2   2.172930e+06    1474.086143       -0.372840       -1.769826  ...   \n",
       "3   1.544999e+06    1242.980012       -0.204804       -1.930438  ...   \n",
       "4   1.703125e+06    1305.038129       -0.369391       -1.923656  ...   \n",
       "\n",
       "   y-axis_min  y-axis_max  z-axis_mean  z-axis_var  z-axis_std  z-axis_skew  \\\n",
       "0    -14.6690     6.77110     3.955801   18.754033    4.330593     0.008089   \n",
       "1    -15.2855     5.15601     5.059120   23.705820    4.868862     0.811003   \n",
       "2    -13.5641    12.41910     7.476966   31.410942    5.604547     0.750276   \n",
       "3    -12.2669    12.31840     2.758507   19.977624    4.469634    -0.527023   \n",
       "4    -10.6631     6.88393     5.550876   34.808410    5.899865     2.021176   \n",
       "\n",
       "   z-axis_kurt  z-axis_median  z-axis_min  z-axis_max  \n",
       "0     0.209104       3.385215   -3.876750    11.03760  \n",
       "1    -0.350633       3.827275   -0.649272    13.29150  \n",
       "2    -1.243794       5.326455    0.925382    15.89050  \n",
       "3     1.913948       2.881975   -6.676230     9.96933  \n",
       "4     5.310004       4.505560   -1.062830    20.57610  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In the process of feature extraction, the original data was erased for some reason\n",
    "new_df['timestamp'] = sample['timestamp']\n",
    "new_df['activityID'] = sample['activityID']\n",
    "new_df['x-axis'] = sample['x-axis']\n",
    "new_df['y-axis'] = sample['y-axis']\n",
    "new_df['z-axis'] = sample['z-axis']\n",
    "new_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05fcd3",
   "metadata": {},
   "source": [
    "### Normalization and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1baf1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The article says it uses correlation to select which features to use in the models. Here x-axis and\n",
    "# y-axis are the only ones left. The article gets jumbled up between depicting several datasets, so I might\n",
    "# of cross the wires somewhere. Since its focusing on 3d movement, I'm leaving z-axis in, I just want to \n",
    "# make note of this to show that it is not being ignored.\n",
    "corr = new_df.corr().abs()\n",
    "corr[corr['activityID']>0.25].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd42cf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#se = StandardScaler()\n",
    "se = MinMaxScaler(feature_range = (0, 1))\n",
    "X = new_df.drop('activityID', axis=1)\n",
    "X = se.fit_transform(X)\n",
    "y = new_df['activityID']\n",
    "new_df.to_csv('out.csv')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cc8007fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f4b89c",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a2e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(random_state=42, max_depth=20),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23c95e",
   "metadata": {},
   "source": [
    "# Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "boost_clf = BaggingClassifier(\n",
    "    base_estimator=GradientBoostingClassifier(random_state=42, max_depth=20),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "boost_clf.fit(X_train,y_train)\n",
    "boost_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c30a7",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816f4acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "    base_estimator=RandomForestCLassifier(random_state=42, max_depth=20),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "bag_clf.fit(X_train,y_train)\n",
    "bag_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba13745f",
   "metadata": {},
   "source": [
    "# Weighted Majority Voting Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301c67d",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3a908f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The researchers used a decision tree with a depth of 20\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = BaggingClassifier(\n",
    "    base_estimator=DecisionTreeClassifier(random_state=42, max_depth=20),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "dt_clf.fit(X_train,y_train)\n",
    "dt_pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c3490",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "442bcda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Within the article they use 7 neighbors.\n",
    "k_clf = BaggingClassifier(\n",
    "    base_estimator=KNeighborsClassifier(n_neighbors=7),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "k_clf.fit(X_train,y_train)\n",
    "k_pred = k_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dcf1bc",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "52b64f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC # Support vector machine\n",
    "# Implement a 'one-vs-rest' type SVM\n",
    "# This is definately the most time expensive to implement.\n",
    "svm_clf = BaggingClassifier(\n",
    "    base_estimator=SVC(decision_function_shape='ovr', probability=True, kernel='linear'),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "svm_clf.fit(X_train,y_train)\n",
    "svm_pred = svm_clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c8e053",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1da46608",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\David\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier # ANN\n",
    "# 50 neurons in the hidden layer\n",
    "# linear activation 'ReLu'\n",
    "# learning rate = 0.001\n",
    "# 100 epochs\n",
    "ann_clf = BaggingClassifier(\n",
    "    base_estimator=MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, random_state=42),\n",
    "    n_estimators = 100, # Number of base estimators in the esemble.\n",
    "    max_samples=0.05, # Percent of training data taken\n",
    "    oob_score=True, # Replacement implemented\n",
    "    random_state=42\n",
    ")\n",
    "ann_clf.fit(X_train,y_train)\n",
    "ann_pred = ann_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c120bc2",
   "metadata": {},
   "source": [
    "### Weighted Majority Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f5795a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('BDT',\n",
       "                              BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=20,\n",
       "                                                                                      random_state=42),\n",
       "                                                max_samples=0.05,\n",
       "                                                n_estimators=100,\n",
       "                                                oob_score=True,\n",
       "                                                random_state=42)),\n",
       "                             ('knn',\n",
       "                              BaggingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=7),\n",
       "                                                max_samples=0.05,\n",
       "                                                n_estimators=100,\n",
       "                                                oob_score=True,\n",
       "                                                random_state=42)),\n",
       "                             ('svm',\n",
       "                              BaggingClassifier(base_estimator=SVC(kernel='linear',\n",
       "                                                                   probability=True),\n",
       "                                                max_samples=0.05,\n",
       "                                                n_estimators=100,\n",
       "                                                oob_score=True,\n",
       "                                                random_state=42)),\n",
       "                             ('ann',\n",
       "                              BaggingClassifier(base_estimator=MLPClassifier(hidden_layer_sizes=(50,),\n",
       "                                                                             max_iter=100,\n",
       "                                                                             random_state=42),\n",
       "                                                max_samples=0.05,\n",
       "                                                n_estimators=100,\n",
       "                                                oob_score=True,\n",
       "                                                random_state=42))],\n",
       "                 n_jobs=-1, voting='soft')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier \n",
    "wmv_clf = VotingClassifier(estimators=[\n",
    "     ('BDT', dt_clf)\n",
    "    ,('knn', k_clf)\n",
    "    ,('svm',svm_clf)\n",
    "    ,('ann', ann_clf)], voting='soft', n_jobs=-1)\n",
    "\n",
    "wmv_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89d4bb",
   "metadata": {},
   "source": [
    "### NB combination \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b8778fc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-1c4d028c27fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnb_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mnb_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 638\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    639\u001b[0m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    769\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m         \u001b[1;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m         \u001b[0mcheck_non_negative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[1;34m(X, whom)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train,y_train)\n",
    "\n",
    "nb_pred = nb_clf.predict(X_test)\n",
    "\n",
    "acc_score = accuracy_score(y_test, y_pred)\n",
    "conf_mat = confusion_matrix(\n",
    "        y_test, y_pred)\n",
    "\n",
    "print(acc_score)\n",
    "print(conf_mat)\n",
    "\n",
    "\n",
    "#wmv_pred = wmv_clf.predict(X_test)\n",
    "#confusion_matrix(wmv_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "21a0e87b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[315,   1,   2,   0,   0,   0,   0],\n",
       "       [  4, 291,  17,   0,   0,   0,   0],\n",
       "       [  5,  19, 335,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 353,   5,  10,   8],\n",
       "       [  0,   0,   0,   0, 101,   0,   0],\n",
       "       [  0,   0,   0,  13,  31, 232,  11],\n",
       "       [  0,   0,   0,   5,  19,   7, 216]], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmv_pred = wmv_clf.predict(X_test)\n",
    "confusion_matrix(wmv_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4442124",
   "metadata": {},
   "source": [
    "# Evaluation and Results\n",
    "There is an analysis of the precision between Weighted Majority Vote and the other models. In the article they did the exact same, difference being they added f1_scoring with a cross validation with a LeaveOneOut splitting strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0b77491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9215"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmv_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1bd288f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ann: {0.112}\n",
      "BDT: {0.0205}\n",
      "SVM: {0.1395}\n",
      "knn: {0.153}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Ann:', {wmv_clf.named_estimators_['ann'].score(X_test, y_test)})\n",
    "print('BDT:', {wmv_clf.named_estimators_['BDT'].score(X_test, y_test)})\n",
    "print('SVM:', {wmv_clf.named_estimators_['svm'].score(X_test, y_test)})\n",
    "print('knn:', {wmv_clf.named_estimators_['knn'].score(X_test, y_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "745a9a0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BaggingClassifier' object has no attribute 'cross_val_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-81df611c718c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m results = ann_clf.cross_val_score(estimator=model,\n\u001b[0m\u001b[0;32m     13\u001b[0m                                           \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BaggingClassifier' object has no attribute 'cross_val_score'"
     ]
    }
   ],
   "source": [
    "# (LOSO) Cross-validation\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "scoring = {'accuracy' : make_scorer(accuracy_score), \n",
    "           'precision' : make_scorer(precision_score),\n",
    "           'recall' : make_scorer(recall_score), \n",
    "           'f1_score' : make_scorer(f1_score)}\n",
    "\n",
    "#kfold = model_selection.KFold(n_splits=10, random_state=42)\n",
    "model=MLPClassifier(hidden_layer_sizes=(50,), max_iter=100, random_state=42)\n",
    "\n",
    "results = ann_clf.cross_val_score(estimator=model,\n",
    "                                          X=features,\n",
    "                                          y=labels,\n",
    "                                          cv=LeaveOneOut(),#(LOSO)\n",
    "                                          scoring=scoring)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
